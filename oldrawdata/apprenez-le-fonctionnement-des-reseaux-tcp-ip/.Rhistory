byParts$suggestion_title="Réviser ou supprimer la section"
byParts$suggestion_content="La section doit apporter plus d'informations nouvelles / intéressantes :
Si cette section est réellement nécessaire : peut-elle être reformulée, voire intégrée dans un autre chapitre ou une autre section du cours ?
Sinon, la supprimer et revoir le plan du chapitre et du cours."
DurationData = PartData[which(PartData$part_type=='chapitre'),c('part_id','mean.duration')]
byChaps = DurationData[which(DurationData$mean.duration<quantile(DurationData$mean.duration,0.10,na.rm = TRUE) ),]
byChaps$classe="mean.duration"
byChaps$issueCode="RminDuration"
byChaps$content="Temps de lecture trop court"
val = round(median(DurationData$mean.duration,na.rm = TRUE) / byChaps$mean.duration,0)
byChaps$description=paste("Ce chapitre est plutôt survolé : son temps de lecture est",val,"fois inférieur au temps médian")
byChaps$suggestion_title="Réviser ou supprimer le chapitre"
byChaps$suggestion_content="Le chapitre doit apporter plus d'informations nouvelles / intéressantes :
Si  le chapitre est réellement nécessaire : peut-il être reformulé, voire intégré dans un autre chapitre ou  partie du cours ?
Sinon, le supprimer et revoir le plan de la partie chapitre et du cours."
DurationData = PartData[which(PartData$part_type=='partie'),c('part_id','mean.duration')]
byTomes = DurationData[which(DurationData$mean.duration<quantile(DurationData$mean.duration,0.10,na.rm = TRUE) ),]
byTomes$classe="mean.duration"
byTomes$issueCode="RminDuration"
byTomes$content="Temps de lecture trop court"
val = round(median(DurationData$mean.duration,na.rm = TRUE) / byTomes$mean.duration,0)
byTomes$description=paste("Cette partie est plutôt survolée : son temps de lecture est",val,"fois inférieur au temps médian")
byTomes$suggestion_title="Réviser ou supprimer la partie"
byTomes$suggestion_content="La partie doit apporter plus d'informations nouvelles / intéressantes :
Si la partie est réellement nécessaire : peut-elle être reformulée, voire intégrée dans une partie du cours ?
Sinon, la supprimer et revoir le plan du cours."
minDuration =  rbind(byParts,byChaps,byTomes)
################## Vitesse MIN
SpeedData = PartData[which(PartData$part_type=='section'),c('part_id','speed')]
byParts = SpeedData[which(SpeedData$speed>quantile(SpeedData$speed,0.90,na.rm = TRUE) ),]
byParts$classe="speed"
byParts$issueCode="RmaxSpeed"
byParts$content="Vitesse de lecture trop rapide"
val = round(byParts$speed / median(SpeedData$speed,na.rm = TRUE) ,2)
byParts$description=paste("Cette section comporte probablement trop peu d'éléments nouveaux, intéressants : la vitesse moyenne de lecture étant",val,"fois supéreire à la vitesse moyenne de lecture des autres section")
byParts$suggestion_title="Réviser ou supprimer la section"
byParts$suggestion_content="La section doit être plus simple à lire/comprendre :
- utiliser un vocabulaire plus commun ou directement défini dans le texte,
- vérifier l'enchaînement logique des propos
- ajouter des exemples/analogies pour améliorer la compréhension
- éviter les dispersions : aller à l'essentiel"
SpeedData = PartData[which(PartData$part_type=='chapitre'),c('part_id','speed')]
byChaps = SpeedData[which(SpeedData$speed>quantile(SpeedData$speed,0.90,na.rm = TRUE) ),]
byChaps$classe="speed"
byChaps$issueCode="RmaxSpeed"
byChaps$content="Temps de lecture trop court"
val = round(median(SpeedData$speed,na.rm = TRUE) / byChaps$speed,2)
byChaps$description=paste("Ce chapitre  comporte probablement trop peu d'éléments nouveaux, intéressants : la vitesse moyenne de lecture étant",val,"fois supéreire à la vitesse moyenne de lecture des autres chapitres")
byChaps$suggestion_title="Réviser ou supprimer le chapitre"
byChaps$suggestion_content="Le chapitre doit être plus simple à lire/comprendre :
- utiliser un vocabulaire plus commun ou directement défini dans le texte,
- vérifier l'enchaînement logique des propos
- ajouter des exemples/analogies pour améliorer la compréhension
- éviter les dispersions : aller à l'essentiel."
maxSpeed =  rbind(byParts,byChaps)
source('~/dev/CoReaDa/R/nodejs/Fact_nodejs.r', echo=TRUE)
maxSpeed
ReadsData  = PartData[which(PartData$part_type=='section'),c('part_id','rereadings_tx')]
byParts = ReadsData[which(ReadsData$rereadings_tx>quantile(ReadsData$rereadings_tx,0.9,na.rm = TRUE)),]
byParts$classe="rereadings_tx"
byParts$issueCode="RRmax"
byParts$content="Trop de relectures"
byParts$description=paste("Cette section est  en moyenne relue",round(byParts$rereadings_tx/median(ReadsData$rereadings_tx),2),"fois plus que le nombre moyen de relecture des autres sections")
byParts$suggestion_title="Simplifier l'écriture de la section et vérifier l'enchainement"
byParts$suggestion_content="Vérifier les relectures conjointes et disjointes, si il y a globalement équilibre alors :
La section doit être plus simple à  lire et comprendre :
- utiliser un vocabulaire plus commun ou directement défini dans le texte,
- vérifier l'enchaînement logique des propos
- ajouter des exemples/analogies pour améliorer la compréhension
- éviter les dispersions : aller à l'essentiel.
Sinon, regarder l'indicateur de relecture plus spécifique (même séance ou séances disjointes) pour suggestion"
ReadsData  = PartData[which(PartData$part_type=='chapitre'),c('part_id','rereadings_tx')]
byChaps = ReadsData[which(ReadsData$rereadings_tx>quantile(ReadsData$rereadings_tx,0.9,na.rm = TRUE)),]
byChaps$classe="rereadings_tx"
byChaps$issueCode="RRmax"
byChaps$content="Trop de relectures"
byChaps$description=paste("Les sections de ce chapitre sont en moyenne relues",round(byChaps$rereadings_tx/median(ReadsData$rereadings_tx),2),"fois plus que le nombre moyen de relectures des sections des autres chapitres")
byChaps$suggestion_title="Simplifier l'écriture du chapitre et vérifier l'enchainement des sections"
byChaps$suggestion_content="Vérifier les relectures conjointes et disjointes, si il y a globalement équilibre alors :
Le chapitre et ses sections doivent être plus simples à  lire et comprendre :
- utiliser un vocabulaire plus commun ou directement défini dans le texte,
- vérifier l'enchaînement logique des propos
- ajouter des exemples/analogies pour améliorer la compréhension
- éviter les dispersions : aller à  l'essentiel.
Sinon, regarder l'indicateur de relecture plus spécifique (même séance ou séances disjointes) pour suggestion"
ReadsData = PartData[which(PartData$part_type=='partie'),c('part_id','rereadings_tx')]
byTomes = ReadsData[which(ReadsData$rereadings_tx>quantile(ReadsData$rereadings_tx,0.9,na.rm = TRUE)),]
byTomes$classe="rereadings_tx"
byTomes$issueCode="RRmax"
byTomes$content="Trop de relectures"
byTomes$description=paste("Les sections de cette partie sont en moyenne relues",round(byTomes$rereadings_tx/median(ReadsData$rereadings_tx),2),"fois plus que le nombre moyen de relectures des sections des autres parties")
byTomes$suggestion_title="Simplifier l'écriture de la partie et vérifier l'enchainement de ses chapitres"
byTomes$suggestion_content="Vérifier les relectures conjointes et disjointes, si il y a globalement équilibre alors :
La partie  et ses chapitres et sections doivent être plus simples à  lire et comprendre :
- utiliser un vocabulaire plus commun ou directement défini dans le texte,
- vérifier l'enchaînement logique des propos
- ajouter des exemples/analogies pour améliorer la compréhension
- éviter les dispersions : aller à  l'essentiel.
Sinon, regarder l'indicateur de relecture plus spécifique (même séance ou séances disjointes) pour suggestion"
maxRereadings =  rbind(byParts,byChaps,byTomes)
# arrets définitif de la lecture
StopData = PartData[which(PartData$part_type=='section'),c('part_id','norecovery_tx')]
byParts = StopData[which(StopData$norecovery_tx>quantile(StopData$norecovery_tx,0.9,na.rm = TRUE)),]
byParts$classe="norecovery_tx"
byParts$issueCode="StopRSExit"
byParts$content=paste("Trop d'arrêts définitifs de la lecture sur cette section")
byParts$description=paste(round(100*byParts$norecovery_tx,2), "% des fins définitives de la lecture  (sans reprises ultérieures) se passent sur cette section. ")
byParts$suggestion_title="Réécrire et simplifier cette section"
byParts$suggestion_content="Cette section a besoin d\'être plus simple à lire et à comprendre :
- utiliser un vocabulaire plus commun ou directement défini dans le texte,
- vérifier l'enchaînement logique des propos
- ajouter des exemples/analogies pour améliorer la compréhension
- éviter les dispersions : aller à l\'essentiel"
StopData = PartData[which(PartData$part_type=='chapitre'),c('part_id','norecovery_tx')]
byChaps = StopData[which(StopData$norecovery_tx>quantile(StopData$norecovery_tx,0.9,na.rm = TRUE)),]
byChaps$classe="norecovery_tx"
byChaps$issueCode="StopRSExit"
byChaps$content=paste("Trop d'arrêts définitifs de la lecture sur ce chapitre")
byChaps$description=paste(round(100*byChaps$norecovery_tx,2), "% des fins définitives de la lecture  (sans reprises ultérieures) se passent sur ce chapitre.")
byChaps$suggestion_title="Réécrire et simplifier ce chapitre"
byChaps$suggestion_content="Ce chapitre a besoin d\'être plus simple à lire et à comprendre :
- utiliser un vocabulaire plus commun ou directement défini dans le texte,
- vérifier l'enchaînement logique des propos
- ajouter des exemples/analogies pour améliorer la compréhension
- éviter les dispersions : aller à l\'essentiel"
StopData = PartData[which(PartData$part_type=='partie'),c('part_id','norecovery_tx')]
byTomes = StopData[which(StopData$norecovery_tx>quantile(StopData$norecovery_tx,0.9,na.rm = TRUE)),]
byTomes$classe="norecovery_tx"
byTomes$issueCode="StopRSExit"
byTomes$content=paste("Trop d'arrêts définitifs de la lecture sur cette partie")
byTomes$description=paste(round(100*byTomes$norecovery_tx), "% des fins définitives de la lecture  (sans reprises ultérieures) se passent sur cette partie.")
byTomes$suggestion_title="Réécrire et simplifier cette partie"
byTomes$suggestion_content="Cette partie a besoin d\'être plus simple à lire et à comprendre :
- utiliser un vocabulaire plus commun ou directement défini dans le texte,
- vérifier l'enchaînement logique des propos
- ajouter des exemples/analogies pour améliorer la compréhension
- éviter les dispersions : aller à l\'essentiel"
maxFinalStops =  rbind(byParts,byChaps,byTomes)
names(minVisits)[c(1,2)]=
names(minDuration)[c(1,2)]=
names(maxRereadings)[c(1,2)]=
maxSpeed[c(1,2)]=
names(maxFinalStops)[c(1,2)]=c("part_id","value")
facts =
rbind(
minVisits,
minDuration,
maxSpeed,
maxRereadings,
maxFinalStops)
maxFinalStops
maxSpeed
names(maxSpeed)[c(1,2)]
maxRereadings
names(minVisits)[c(1,2)]=
names(minDuration)[c(1,2)]=
names(maxRereadings)[c(1,2)]=
names(maxSpeed)[c(1,2)]=
names(maxFinalStops)[c(1,2)]=c("part_id","value")
facts =
rbind(
minVisits,
minDuration,
maxSpeed,
maxRereadings,
maxFinalStops)
save(facts, file="nodejs.facts.rdata")
library('jsonlite')
library('reshape')
facts.json = toJSON(unname(split(facts, 1:nrow(facts))))
cat(facts.json, file="facts.json")
save(PartData, file='PartData.rdata')
colnames(PartData)[1]="id"
colnames(PartData)[3]="parent_id"
colnames(PartData)[1]="part_id"
names(PartData)
colnames(PartData)[1]="id"
colnames(PartData)[3]="parent_id"
meltParts=melt(PartData, id.vars = 'id')
PartsData.json = toJSON(unname(split(meltParts,1:nrow(meltParts))))
cat(PartsData.json, file="structure.json")
max(PartData$speed)
max(PartData$speed, na.rm=TRUE)
maxSpeed
View(maxSpeed)
View(facts)
facts=facts[which(facts$classe!='speed'),]
View(facts)
SpeedData = PartData[which(PartData$part_type=='section'),c('part_id','speed')]
SpeedData
byParts = SpeedData[which(SpeedData$speed>quantile(SpeedData$speed,0.90,na.rm = TRUE) ),]
byParts$classe="speed"
byParts$issueCode="RmaxSpeed"
byParts$content="Vitesse de lecture trop rapide"
val = round(byParts$speed / median(SpeedData$speed,na.rm = TRUE) ,2)
byParts$description=paste("Cette section comporte probablement trop peu d'éléments nouveaux, intéressants : la vitesse moyenne de lecture étant",val,"fois supéreire à la vitesse moyenne de lecture des autres section")
byParts$suggestion_title="Réviser ou supprimer la section"
byParts$suggestion_content="La section doit être plus simple à lire/comprendre :
- utiliser un vocabulaire plus commun ou directement défini dans le texte,
- vérifier l'enchaînement logique des propos
- ajouter des exemples/analogies pour améliorer la compréhension
- éviter les dispersions : aller à l'essentiel"
SpeedData = PartData[which(PartData$part_type=='chapitre'),c('part_id','speed')]
byChaps = SpeedData[which(SpeedData$speed>quantile(SpeedData$speed,0.90,na.rm = TRUE) ),]
byChaps$classe="speed"
byChaps$issueCode="RmaxSpeed"
byChaps$content="Temps de lecture trop court"
val = round(median(SpeedData$speed,na.rm = TRUE) / byChaps$speed,2)
byChaps$description=paste("Ce chapitre  comporte probablement trop peu d'éléments nouveaux, intéressants : la vitesse moyenne de lecture étant",val,"fois supéreire à la vitesse moyenne de lecture des autres chapitres")
byChaps$suggestion_title="Réviser ou supprimer le chapitre"
byChaps$suggestion_content="Le chapitre doit être plus simple à lire/comprendre :
- utiliser un vocabulaire plus commun ou directement défini dans le texte,
- vérifier l'enchaînement logique des propos
- ajouter des exemples/analogies pour améliorer la compréhension
- éviter les dispersions : aller à l'essentiel."
maxSpeed =  rbind(byParts,byChaps)
maxSpeed
names(maxSpeed)[c(1,2)]
names(maxSpeed)[c(1,2)]=c("part_id","value")
names(maxSpeed)[c(1,2)]
facts=rbond(facts,maxSpeed)
facts=rbind(facts,maxSpeed)
View(facts)
save(facts, file="nodejs.facts.rdata")
facts.json = toJSON(unname(split(facts, 1:nrow(facts))))
cat(facts.json, file="facts.json")
options(stringsAsFactors=FALSE)
library('jsonlite')
library('reshape')
setwd("E:/DEV/CoReaDa/R/nodejs")
BaseURL="E:/DEV/CoReaDa/R/nodejs"
setwd(BaseURL)
load('metacourses.rdata')
options(stringsAsFactors=FALSE)
library('jsonlite')
library('reshape')
BaseURL = ('/home/madjid/Dropbox/rcoreada')
BaseURL="C:/Users/MADJID/Desktop/rcoreada"
setwd(BaseURL)
load('metacourses.rdata')
range01 <- function(x, ...){(x - min(x, ...)) / (max(x, ...) - min(x, ...))}
course_nb  = 2
selectedCourse = courses[course_nb,]$slug
selectedId = courses[course_nb,]$course_id
setwd(paste(BaseURL,selectedCourse, sep='/'))
load('data.rdata')
load('structure.rdata')
load('Interest.rdata')
load('Reads.rdata')
load('Ruptures.rdata')
load('RS.rdata')
load('partFollow.rdata')
head(RS)
CourseData$RS_meanparts = mean(RS$nparts)
mean(RS$nparts)
median(RS$nparts)
mean(RS$duration)
median(RS$duration)
median(RS$duration)/60
median(RS$duration)/60000
median(RS$duration)
median(RS$duration)/1000
RS$duration
median(RS$duration)
min(RS$duration)
median(RS$duration)
median(RS$duration)/1000
load('data.rdata')
load('structure.rdata')
load('Interest.rdata')
load('Reads.rdata')
load('Ruptures.rdata')
load('RS.rdata')
load('partFollow.rdata')
load('PartData.rdata')
users=unique(data$user_id)
nusers=length(users)
nusers
CourseData$RS_meanparts = mean(RS$nparts)
nusers/nrow(RS)
nusers
nrow(RS)
length(unique(data[,c('user_id','seance')]))
nrow(unique(data[,c('user_id','seance')]))
nrow(unique(data[,c('user_id')]))
nrow(unique(data$user_id))
lenght(unique(data$user_id))
length(unique(data$user_id))
nusers
nusers/nrow(RS)
nrow(RS)/nusers
PartData[PartData$type=='course',]$reading_not_linear
course_nb  = 2
selectedCourse = courses[course_nb,]$slug
selectedId = courses[course_nb,]$course_id
setwd(paste(BaseURL,selectedCourse, sep='/'))
load('data.rdata')
load('structure.rdata')
load('Interest.rdata')
load('Reads.rdata')
load('Ruptures.rdata')
load('RS.rdata')
load('partFollow.rdata')
print(paste('Cours', course_nb,'/',nrow(courses),': ',PartData[which(PartData$type=='course'),]$title))
courses[course_nb,]$Title = structure[which(structure$type=='course'),]$title
################################# PARTDATA ########################################################
PartData = structure
nParties = nrow(PartData[which(PartData$part_index==0),])
PartData[which(PartData$part_index==0),]$part_index=-1*(0:(nParties-1))
PartData[which(PartData$type=='title-1'),]$type='partie'
PartData[which(PartData$type=='title-2'),]$type='chapitre'
if(nrow(PartData[which(PartData$type=='title-3'),])>0)
PartData[which(PartData$type=='title-3'),]$type='section'
############## SIZE : 1s video --> 2 mots. 1 image --> 30 mots
if("vid_length" %in% colnames(PartData))
{
print("vids exist")
PartData$size = PartData$size + PartData$vid_length * 2
}
if("nb_img" %in% colnames(PartData))
{
print("imgs exist")
PartData$size = PartData$size +  PartData$nb_img * 30
}
tomesIds = PartData[which(PartData$type=='partie'),]$part_id
for(i in 1:length(tomesIds)){
PartData[which(PartData$part_id==tomesIds[i]),]$size =  sum(PartData[which(PartData$parent_id==tomesIds[i]),]$size)
}
PartData$speed=round(PartData$size/(PartData$mean.duration/60),2)
PartData[is.na(PartData$speed),]$speed <- -1
save(PartData, file='PartData.rdata')
#################Prepare Transitions#####################
part_indexes=1:(max(structure$part_index))
Transitions = merge(data.frame(y=part_indexes),data.frame(x=part_indexes))
Transitions = Transitions [,c('x','y')]
Transitions$provenance  = 0
Transitions$destination  = 0
for(aPart in 1:max(structure$part_index))
{
partFollow[aPart,aPart]=0
}
partPrecedent <- t(partFollow)
for(aPart in 1:max(structure$part_index))
{
nodes_dest = data.frame(part=1:(nrow(partFollow)), frequence=partFollow[aPart,])
nodes_dest$ratio = nodes_dest$frequence/sum(nodes_dest$frequence)
for(partDest in 1:max(structure$part_index)){
Transitions[which((Transitions$x==aPart)&(Transitions$y==partDest)),]$destination=
nodes_dest[nodes_dest$part==partDest,]$ratio
}
nodes_prov = data.frame(part=1:(nrow(partFollow)), frequence=partPrecedent[aPart,])
nodes_prov$ratio = nodes_prov$frequence/sum(nodes_prov$frequence)
for(partProv in 1:max(structure$part_index)){
Transitions[which((Transitions$x==aPart)&(Transitions$y==partProv)),]$provenance=
nodes_prov[nodes_prov$part==partProv,]$ratio
}
}
TransitionsData=merge(Transitions, structure[,c('part_index','part_id')],by.x = 'x', by.y='part_index',all.x = TRUE)
TransitionsData=TransitionsData[,c('part_id','y','provenance','destination')]
names(TransitionsData)[1]='x'
TransitionsData=merge(TransitionsData, structure[,c('part_index','part_id')],by.x = 'y', by.y='part_index',all.x = TRUE)
TransitionsData=TransitionsData[,c('x','part_id','provenance','destination')]
names(TransitionsData)[2]='y'
TransitionsData.json = toJSON(TransitionsData)
cat(TransitionsData.json, file="navigation.json")
Destinations_stats = data.frame(part_index=part_indexes,destination_next=0.0,destination_past=0.0,
destination_future=0.0, destination_not_linear=0.0)
for(aPart in 1:max(structure$part_index))
{
partDestinations=Transitions[Transitions$x==aPart,c('y','destination')]
Destinations_stats[Destinations_stats$part_index==aPart,]$destination_past =
sum(partDestinations[partDestinations$y<aPart,]$destination)
Destinations_stats[Destinations_stats$part_index==aPart,]$destination_future =
sum(partDestinations[partDestinations$y>aPart+1,]$destination)
if(aPart<max(structure$part_index))
Destinations_stats[Destinations_stats$part_index==aPart,]$destination_next =
partDestinations[partDestinations$y==aPart+1,]$destination
Destinations_stats[Destinations_stats$part_index==aPart,]$destination_not_linear =
1.0 - (Destinations_stats[Destinations_stats$part_index==aPart,]$destination_next)
}
Destinations_stats = rbind(c(0,mean(Destinations_stats$destination_next),mean(Destinations_stats$destination_past),
mean(Destinations_stats$destination_future),mean(Destinations_stats$destination_not_linear)),
Destinations_stats)
Provenances_stats = data.frame(part_index=part_indexes,provenance_prev=0.0,provenance_past=0.0,
provenance_future=0.0, provenance_not_linear=0.0)
for(aPart in 1:max(structure$part_index))
{
partProvenances=Transitions[Transitions$x==aPart,c('y','provenance')]
Provenances_stats[Provenances_stats$part_index==aPart,]$provenance_past =
sum(partProvenances[partProvenances$y<aPart-1,]$provenance)
Provenances_stats[Provenances_stats$part_index==aPart,]$provenance_future =
sum(partProvenances[partProvenances$y>aPart,]$provenance)
if(aPart>1)
Provenances_stats[Provenances_stats$part_index==aPart,]$provenance_prev =
partProvenances[partProvenances$y==aPart-1,]$provenance
Provenances_stats[Provenances_stats$part_index==aPart,]$provenance_not_linear =
1.0 - (Provenances_stats[Provenances_stats$part_index==aPart,]$provenance_prev)
}
Provenances_stats = rbind(c(0,mean(Provenances_stats$provenance_prev),mean(Provenances_stats$provenance_past),
mean(Provenances_stats$provenance_future),mean(Provenances_stats$provenance_not_linear)),
Provenances_stats)
#################Interest####################
users=unique(data$user_id)
nusers=length(users)
PartData = merge(PartData, Reads[,-c(1)], all.x = TRUE)
PartData = merge(PartData, Interest[,c('part_id','RS_nb')], all.x = TRUE)
rs_nb = Interest[which(Interest$part_id== structure[which(structure$type=='course'),]$part_id),]$RS_nb
PartData$Actions_tx = PartData$Actions_nb / nrow(data)
PartData$readers_tx = PartData$Readers / nusers
PartData$rs_tx = PartData$RS_nb / rs_nb
minspeed = min(PartData[PartData$speed>0,]$speed)
maxspeed = max(PartData[PartData$speed>0,]$speed)
PartData$invspeed = -1
PartData[PartData$speed>0,]$invspeed = maxspeed- PartData[PartData$speed>0,]$speed
PartData[PartData$speed>0,]$invspeed =range01(PartData[PartData$speed>0,]$invspeed, na.rm=TRUE)
PartData$interest = PartData$readers_tx + PartData$rs_tx + PartData$invspeed
PartData[PartData$interest>0,]$interest = range01(PartData[PartData$interest>0,]$interest, na.rm=TRUE)
#################FIN####################
PartData = merge(PartData, Provenances_stats,  by = 'part_index',all.x = TRUE)
PartData = merge(PartData, Destinations_stats,  by = 'part_index',all.x = TRUE)
PartData$reading_not_linear = PartData$provenance_not_linear+ PartData$destination_not_linear
PartData$reading_not_linear = range01(PartData$reading_not_linear, na.rm=TRUE)
PartData = merge(PartData, Ruptures[,-c(1)], all.x = TRUE)
PartData$recovery=PartData$direct_recovery+PartData$distant_next_recovery+PartData$distant_prev_recovery+PartData$next_recovery+PartData$prev_recovery
PartData$norecovery=PartData$rupture-PartData$recovery
allRup = max(PartData$rupture, na.rm=TRUE)
finalRupt = max(PartData$norecovery, na.rm=TRUE)
PartData$rupture_tx = PartData$rupture/allRup
PartData$norecovery_tx = PartData$norecovery/finalRupt
PartData$resume_future= (PartData$distant_next_recovery)/PartData$recovery
PartData$resume_past= (PartData$prev_recovery+PartData$distant_prev_recovery)/PartData$recovery
PartData$resume_abnormal_tx = PartData$resume_future + PartData$resume_past
################### RELECTURE ######################################
PartData$rereads_tx = 0
PartData$rereads_globratio = 0
allRereads = sum(PartData[which(PartData$type=='chapitre'),]$Rereadings, na.rm=TRUE)
PartData[which(PartData$type=='chapitre'),]$rereads_tx =  PartData[which(PartData$type=='chapitre'),]$Rereadings / PartData[which(PartData$type=='chapitre'),]$Readings
PartData[which(PartData$type=='chapitre'),]$rereads_globratio =  PartData[which(PartData$type=='chapitre'),]$Rereadings / allRereads
# for chapters
tomeIds = PartData[which(PartData$type=='partie'),]$part_id
for(i in 1:length(tomeIds)){
PartData[which(PartData$part_id==tomeIds[i]),]$rereads_tx =  mean(PartData[which(PartData$parent_id==tomeIds[i]),]$rereads_tx)
PartData[which(PartData$part_id==tomeIds[i]),]$rereads_globratio =  mean(PartData[which(PartData$parent_id==tomeIds[i]),]$rereads_globratio)
}
PartData$mean.tx_total_rereaders = round(100 * PartData$Rereaders / PartData$Readers, 2)
PartData$mean.tx_total_readers = round(100 * PartData$Rereaders / nusers, 2)
PartData$rereads_seq_tx = 0
PartData$rereads_seq_globratio = 0
sumseq = sum(PartData[which(PartData$type=='chapitre'),]$Sequential_rereadings, na.rm=TRUE)
PartData[which(PartData$type=='chapitre'),]$rereads_seq_tx =  PartData[which(PartData$type=='chapitre'),]$Sequential_rereadings / PartData[which(PartData$type=='chapitre'),]$Rereadings
PartData[which(PartData$type=='chapitre'),]$rereads_seq_globratio = PartData[which(PartData$type=='chapitre'),]$Sequential_rereadings / sumseq
# for tomes
tomeIds = PartData[which(PartData$type=='partie'),]$part_id
for(i in 1:length(tomeIds)){
PartData[which(PartData$part_id==tomeIds[i]),]$rereads_seq_tx =  mean(PartData[which(PartData$parent_id==tomeIds[i]),]$rereads_seq_tx)
}
# for all course
PartData[which(PartData$type=='course'),]$rereads_seq_tx =  mean(PartData[which(PartData$type=='chapitre'),]$rereads_seq_tx)
PartData[which(PartData$type=='course'),]$rereads_seq_globratio =  mean(PartData[which(PartData$type=='chapitre'),]$rereads_seq_globratio)
PartData$rereads_dec_tx = 0
PartData$rereads_dec_globratio = 0
sumdec = sum(PartData[which(PartData$type=='chapitre'),]$Decaled_rereadings, na.rm=TRUE)
PartData[which(PartData$type=='chapitre'),]$rereads_dec_tx =  PartData[which(PartData$type=='chapitre'),]$Decaled_rereadings / PartData[which(PartData$type=='chapitre'),]$Rereadings
PartData[which(PartData$type=='chapitre'),]$rereads_dec_globratio =  PartData[which(PartData$type=='chapitre'),]$Decaled_rereadings / sumdec
# for chapters
tomeIds = PartData[which(PartData$type=='partie'),]$part_id
for(i in 1:length(tomeIds)){
PartData[which(PartData$part_id==tomeIds[i]),]$rereads_dec_tx =  mean(PartData[which(PartData$parent_id==tomeIds[i]),]$rereads_dec_tx)
PartData[which(PartData$part_id==tomeIds[i]),]$rereads_dec_globratio =  mean(PartData[which(PartData$parent_id==tomeIds[i]),]$rereads_dec_globratio)
}
# for all course
PartData[which(PartData$type=='course'),]$rereads_dec_tx =  mean(PartData[which(PartData$type=='chapitre'),]$rereads_dec_tx)
PartData[which(PartData$type=='course'),]$rereads_dec_globratio =  mean(PartData[which(PartData$type=='chapitre'),]$rereads_dec_globratio)
####################FIN####################
PartData=PartData[,c("part_index","part_id","parent_id","title","type", "slug", "max.duration"  ,  "mean.duration"  ,
"median.duration" ,"q1.duration" , "q3.duration", "size", "speed" ,"interest" , "Actions_nb",
"Readers", "Rereaders" , "Readings","readers_tx", "Actions_tx","rs_tx",
"Rereadings", "rereads_tx","rereads_globratio", "rereads_seq_tx" , "rereads_seq_globratio" , "rereads_dec_tx","rereads_dec_globratio", "Sequential_rereadings" ,"Decaled_rereadings",
"rereads_tx","part_readers_rereaders"  , "course_readers_rereaders" , "reading_not_linear",
"provenance_prev" , "provenance_not_linear", "provenance_past",  "provenance_future" ,
"destination_next", "destination_not_linear","destination_past" ,"destination_future"  ,
"rupture_tx", "norecovery_tx","resume_abnormal_tx" ,"resume_past","resume_future")]
colnames(PartData)[1]="id"
####################Arrange structure
st = PartData[PartData$id>0,c('id','parent_id')]
st=unique(st[order(st$id),]$parent_id)
st = data.frame(part_id=st, tome_index=1:length(st))
PartData=merge(PartData,st,all.x = TRUE)
#write.csv2(structure,'structure.csv')
#MANUALLY !!!!!!!!!!!!!!!!!!!
#structure = read.csv('structure.csv', stringsAsFactors=FALSE)
#save(structure, file="structure.rdata")
#View(PartData[,c('tome_index','chap_index','part_index')])
save(PartData, file='PartData.rdata')
#################### EXPORT
meltParts=melt(PartData, id.vars = 'id')
########## Stats
CourseData = data.frame(id=0, title=PartData[PartData$type=='course','title'])
CourseData$nactions =sum(PartData[PartData$type=='chapitre','Actions_nb'])
CourseData$nusers =length(unique(data$user_id))
CourseData$nRS = nrow(RS)
CourseData$RS_meanparts = mean(RS$nparts)
CourseData$RS_meanperuser = nrow(RS)/nusers
CourseData$ob_begin=as.character(min(data$date))
CourseData$ob_end=as.character(max(data$date))
meltedCourseStats = melt(CourseData,  id.vars ="id")
meltedCourseData = rbind(meltParts,meltedCourseStats)
if(nrow(meltedCourseData[is.nan(meltedCourseData$value),])>0) meltedCourseData[is.nan(meltedCourseData$value),]$value=0
if(nrow(meltedCourseData[is.na(meltedCourseData$value),])>0) meltedCourseData[is.na(meltedCourseData$value),]$value=0
CourseData.json = toJSON(meltedCourseData)
cat(CourseData.json, file="data.json")
View(t(PartData[PartData$type=='course',]))
