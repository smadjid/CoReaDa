PartData = merge(PartData, Provenances_stats,  by = 'part_index',all.x = TRUE)
PartData = merge(PartData, Destinations_stats,  by = 'part_index',all.x = TRUE)
PartData$reading_not_linear = (PartData$provenance_not_linear+ PartData$destination_not_linear )/3
#PartData$reading_not_linear = range01(PartData$reading_not_linear, na.rm=TRUE)
PartData = merge(PartData, Ruptures[,-c(1)], all.x = TRUE)
PartData$recovery=PartData$direct_recovery+PartData$distant_next_recovery+PartData$distant_prev_recovery+PartData$next_recovery+PartData$prev_recovery
PartData$norecovery=PartData$rupture-PartData$recovery
allRup = max(PartData$rupture, na.rm=TRUE)
finalRupt = max(PartData$norecovery, na.rm=TRUE)
PartData$rupture_tx = PartData$rupture/allRup
PartData$norecovery_tx = PartData$norecovery/finalRupt
PartData$resume_future= (PartData$distant_next_recovery)/PartData$recovery
PartData$resume_past= (PartData$prev_recovery+PartData$distant_prev_recovery)/PartData$recovery
PartData$resume_abnormal_tx = PartData$resume_future + PartData$resume_past
################### RELECTURE ######################################
PartData$rereads_tx = 0
PartData$rereads_globratio = 0
allRereads = sum(PartData[which(PartData$type=='chapitre'),]$Rereadings, na.rm=TRUE)
PartData[which(PartData$type=='chapitre'),]$rereads_tx =  PartData[which(PartData$type=='chapitre'),]$Rereadings / PartData[which(PartData$type=='chapitre'),]$Readings
PartData[which(PartData$type=='chapitre'),]$rereads_globratio =  PartData[which(PartData$type=='chapitre'),]$Rereadings / allRereads
# for chapters
tomeIds = PartData[which(PartData$type=='partie'),]$part_id
for(i in 1:length(tomeIds)){
PartData[which(PartData$part_id==tomeIds[i]),]$rereads_tx =  mean(PartData[which(PartData$parent_id==tomeIds[i]),]$rereads_tx)
PartData[which(PartData$part_id==tomeIds[i]),]$rereads_globratio =  mean(PartData[which(PartData$parent_id==tomeIds[i]),]$rereads_globratio)
}
PartData$mean.tx_total_rereaders = round(100 * PartData$Rereaders / PartData$Readers, 2)
PartData$mean.tx_total_readers = round(100 * PartData$Rereaders / nusers, 2)
PartData$rereads_seq_tx = 0
sumseq = sum(PartData[which(PartData$type=='chapitre'),]$Sequential_rereadings, na.rm=TRUE)
PartData[which(PartData$type=='chapitre'),]$rereads_seq_tx =   PartData[which(PartData$type=='chapitre'),]$Sequential_rereadings / sumseq
# for tomes
tomeIds = PartData[which(PartData$type=='partie'),]$part_id
for(i in 1:length(tomeIds)){
PartData[which(PartData$part_id==tomeIds[i]),]$rereads_seq_tx =  mean(PartData[which(PartData$parent_id==tomeIds[i]),]$rereads_seq_tx)
}
# for all course
PartData[which(PartData$type=='course'),]$rereads_seq_tx =  mean(PartData[which(PartData$type=='chapitre'),]$rereads_seq_tx)
PartData$rereads_dec_tx = 0
sumdec = sum(PartData[which(PartData$type=='chapitre'),]$Decaled_rereadings, na.rm=TRUE)
PartData[which(PartData$type=='chapitre'),]$rereads_dec_tx =   PartData[which(PartData$type=='chapitre'),]$Decaled_rereadings / sumdec
# for chapters
tomeIds = PartData[which(PartData$type=='partie'),]$part_id
for(i in 1:length(tomeIds)){
PartData[which(PartData$part_id==tomeIds[i]),]$rereads_dec_tx =  mean(PartData[which(PartData$parent_id==tomeIds[i]),]$rereads_dec_tx)
}
# for all course
PartData[which(PartData$type=='course'),]$rereads_dec_tx =  mean(PartData[which(PartData$type=='chapitre'),]$rereads_dec_tx)
####################FIN####################
if(dospeed) PartData[PartData$type=='course',]$speed =    mean(PartData[PartData$type=='chapitre',]$speed)
PartData[PartData$type=='course',]$Actions_tx =
mean(PartData[PartData$type=='chapitre',]$Actions_tx)
PartData[PartData$type=='course',]$readers_tx =
mean(PartData[PartData$type=='chapitre',]$readers_tx)
PartData[PartData$type=='course',]$rs_tx =
mean(PartData[PartData$type=='chapitre',]$rs_tx)
PartData[PartData$type=='course',]$rupture_tx =
mean(PartData[PartData$type=='chapitre',]$rupture_tx)
PartData[PartData$type=='course',]$norecovery_tx =
mean(PartData[PartData$type=='chapitre',]$norecovery_tx)
PartData[PartData$type=='course',]$rereads_tx =
mean(PartData[PartData$type=='chapitre',]$rereads_tx)
if(dospeed)
PartData=PartData[,c("part_index","part_id","parent_id","title","type", "slug", "max.duration"  ,  "mean.duration"  ,
"median.duration" ,"q1.duration" , "q3.duration", "size", "speed" ,"interest" , "Actions_nb",
"Readers", "Rereaders" , "Readings","readers_tx", "Actions_tx","rs_tx",
"Rereadings", "rereads_tx", "rereads_seq_tx" ,  "rereads_dec_tx",
"Sequential_rereadings" ,"Decaled_rereadings",  "reading_not_linear",
"provenance_prev" , "provenance_not_linear", "provenance_past",  "provenance_future" ,
"destination_next", "destination_not_linear","destination_past" ,"destination_future"  ,
"rupture_tx", "norecovery_tx","resume_abnormal_tx" ,"resume_past","resume_future")]
if(!dospeed)
PartData=PartData[,c("part_index","part_id","parent_id","title","type", "slug", "max.duration"  ,  "mean.duration"  ,
"median.duration" ,"q1.duration" , "q3.duration", "size", "interest" , "Actions_nb",
"Readers", "Rereaders" , "Readings","readers_tx", "Actions_tx","rs_tx",
"Rereadings", "rereads_tx", "rereads_seq_tx" ,  "rereads_dec_tx",
"Sequential_rereadings" ,"Decaled_rereadings",  "reading_not_linear",
"provenance_prev" , "provenance_not_linear", "provenance_past",  "provenance_future" ,
"destination_next", "destination_not_linear","destination_past" ,"destination_future"  ,
"rupture_tx", "norecovery_tx","resume_abnormal_tx" ,"resume_past","resume_future")]
colnames(PartData)[1]="id"
####################Arrange structure
#st = PartData[PartData$id>0,c('id','parent_id')]
#st=unique(st[order(st$id),]$parent_id)
#st = data.frame(part_id=st, tome_index=1:length(st))
#PartData=merge(PartData,st,all.x = TRUE)
#write.csv2(structure,'structure.csv')
#MANUALLY !!!!!!!!!!!!!!!!!!!
#structure = read.csv('structure.csv', stringsAsFactors=FALSE)
#save(structure, file="structure.rdata")
#View(PartData[,c('tome_index','chap_index','part_index')])
#save(PartData, file='../coursesdata/PartData.rdata')
#################### EXPORT
########## Stats
CourseData = data.frame(id=0, title=PartData[PartData$type=='course','title'])
CourseData$nactions =sum(PartData[PartData$type=='chapitre','Actions_nb'])
CourseData$nusers =length(unique(data$user_id))
CourseData$nRS = nrow(RS)
CourseData$RS_meanparts = mean(RS$nparts)
CourseData$RS_meanperuser = nrow(RS)/nusers
CourseData$ob_begin=as.character(min(data$date))
CourseData$ob_end=as.character(max(data$date))
CourseData$dospeed=dospeed
res = list(PartData=PartData,CourseData=CourseData, TransitionsData=TransitionsData)
return(res)
}
###############  COURSE ISSUES
course_issues_calculation <- function(data, structure,PartData, dospeed){
######################INDICATORS INIT.###############################
minInterest =    # interest
minVisits =   	# Actions_tx
minReaders = 		# readers_tx 			<----------
minRS = 		# rs_tx  			<----------
minSpeed = 		# speed
maxSpeed = 		# speed
maxRereadings = 	# rereads_tx
maxDijRereadings = 	# rereads_dec_tx
maxConjRereadings = 	# rereads_seq_tx
readingLinearity = 	# reading_not_linear  		<----------
provenanceLinearity = 	# provenance_not_linear
provenanceFuture = 	# provenance_future
provenancePast = 	# provenance_past
destinationLinearity = # destination_not_linear
destinationFuture = 	# destination_future
destinationPast = 	# destination_past
maxRSStops = 		# rupture_tx
maxFinalStops = 	# norecovery_tx
resumeLinearity = 	# resume_abnormal_tx  		<----------
recoveryPast = 	# resume_past
recoveryFuture =	#resume_future
data.frame(part_id=integer(),value=character(),classe=character(),issueCode=character(),delta=numeric(),error_value=numeric())
chaptersData = PartData[which(PartData$type=='chapitre'),]
####### TROP PEU D'INTERET
byChaps = chaptersData[(DoubleMADsFromMedian(chaptersData$interest)>1)&(chaptersData$interest<median(chaptersData$interest) ),c('part_id','interest')]
if(nrow(byChaps)>0){
byChaps$classe="interest"
byChaps$issueCode="min"
byChaps$delta  = median(chaptersData$interest,na.rm = TRUE)- byChaps$interest
byChaps$error_value = round(median(chaptersData$interest,na.rm = TRUE)/ byChaps$interest,2)
minInterest = byChaps
}
####### NOMBRE DE VISITES TROP PEU
byChaps = chaptersData[(DoubleMADsFromMedian(chaptersData$Actions_tx)>1)&(chaptersData$Actions_tx<median(chaptersData$Actions_tx) ),c('part_id','Actions_tx')]
if(nrow(byChaps)>0){
byChaps$classe="Actions_tx"
byChaps$issueCode="min"
byChaps$delta  = median(chaptersData$Actions_tx,na.rm = TRUE)- byChaps$Actions_tx
byChaps$error_value = round(median(chaptersData$Actions_tx,na.rm = TRUE)/ byChaps$Actions_tx,2)
minVisits = byChaps
}
####### NOMBRE DE LECTEURS TROP PEU
byChaps = chaptersData[(DoubleMADsFromMedian(chaptersData$readers_tx)>1)&(chaptersData$readers_tx<median(chaptersData$readers_tx) ),c('part_id','readers_tx')]
if(nrow(byChaps)>0){
byChaps$classe="readers_tx"
byChaps$issueCode="min"
byChaps$delta  = median(chaptersData$readers_tx,na.rm = TRUE)- byChaps$readers_tx
byChaps$error_value = round(median(chaptersData$readers_tx,na.rm = TRUE)/ byChaps$readers_tx,2)
minReaders = byChaps
}
####### NOMBRE DE RS TROP PEU
byChaps = chaptersData[(DoubleMADsFromMedian(chaptersData$rs_tx)>1)&(chaptersData$rs_tx<median(chaptersData$rs_tx) ),c('part_id','rs_tx')]
if(nrow(byChaps)>0){
byChaps$classe="rs_tx"
byChaps$issueCode="min"
byChaps$delta  = median(chaptersData$rs_tx,na.rm = TRUE)- byChaps$rs_tx
byChaps$error_value = round(median(chaptersData$rs_tx,na.rm = TRUE)/ byChaps$rs_tx,2)
minRS = byChaps
}
################## Vitesse MAX
if(dospeed){
byChaps = chaptersData[(DoubleMADsFromMedian(chaptersData$speed)>2)&(chaptersData$speed>median(chaptersData$speed) ),c('part_id','speed')]
if(nrow(byChaps)>0){
byChaps$classe="speed"
byChaps$issueCode="max"
byChaps$delta = byChaps$speed - median(chaptersData$speed,na.rm = TRUE)
byChaps$error_value = round(byChaps$speed / median(chaptersData$speed,na.rm = TRUE) ,2)
minSpeed =  byChaps
}
}
################## Vitesse MIN
if(dospeed){
byChaps = chaptersData[(DoubleMADsFromMedian(chaptersData$speed)>1)&(chaptersData$speed<median(chaptersData$speed) ),c('part_id','speed')]
if(nrow(byChaps)>0){
byChaps$classe="speed"
byChaps$issueCode="min"
byChaps$delta = median(chaptersData$speed,na.rm = TRUE) /byChaps$speed
byChaps$error_value = round(median(chaptersData$speed,na.rm = TRUE) /byChaps$speed  ,2)
maxSpeed =  byChaps
}
}
####### MAX REREADINGS
byChaps = chaptersData[(DoubleMADsFromMedian(chaptersData$rereads_tx)>2)&
(chaptersData$rereads_tx>median(chaptersData$rereads_tx) ),c('part_id','rereads_tx')]
if(nrow(byChaps)>0){
byChaps$classe="rereads_tx"
byChaps$issueCode="max"
byChaps$delta=byChaps$rereads_tx-median(chaptersData$rereads_tx)
byChaps$error_value = round(byChaps$rereads_tx/median(chaptersData$rereads_tx),2)
maxRereadings =  byChaps
}
####### Max Conjoint Rereadings
byChaps = chaptersData[(DoubleMADsFromMedian(chaptersData$rereads_seq_tx)>2)&
(chaptersData$rereads_seq_tx>median(chaptersData$rereads_seq_tx) ),c('part_id','rereads_seq_tx')]
if(nrow(byChaps)>0){
byChaps=byChaps[,c('part_id','rereads_seq_tx')]
byChaps$classe="rereads_seq_tx"
byChaps$issueCode="max"
byChaps$delta=byChaps$rereads_seq_tx-median(chaptersData$rereads_seq_tx)
byChaps$error_value = round(byChaps$rereads_seq_tx/median(chaptersData$rereads_seq_tx),2)
maxConjRereadings =  byChaps
}
####### Max Disjoint Rereadings
byChaps = chaptersData[(DoubleMADsFromMedian(chaptersData$rereads_dec_tx)>2)&
(chaptersData$rereads_dec_tx>median(chaptersData$rereads_dec_tx) ),c('part_id','rereads_dec_tx')]
if(nrow(byChaps)>0){
byChaps=byChaps[,c('part_id','rereads_dec_tx')]
byChaps$classe="rereads_dec_tx"
byChaps$issueCode="max"
byChaps$delta=byChaps$rereads_dec_tx-median(chaptersData$rereads_dec_tx)
byChaps$error_value = round(byChaps$rereads_dec_tx/median(chaptersData$rereads_dec_tx),2)
maxDijRereadings =  byChaps
}
####### Reading Linearity
byChaps = chaptersData[(DoubleMADsFromMedian(chaptersData$reading_not_linear)>2)&
(chaptersData$reading_not_linear>median(chaptersData$reading_not_linear) &(chaptersData$id>min(chaptersData$id))&(chaptersData$id<max(chaptersData$id))),c('part_id','reading_not_linear')]
if(nrow(byChaps)>0){
byChaps$classe="reading_not_linear"
byChaps$issueCode="max"
byChaps$delta = byChaps$reading_not_linear
byChaps$error_value =round(100*byChaps$reading_not_linear,2)
readingLinearity = byChaps
}
####### Provenance Linearity
byChaps=subset(chaptersData, (chaptersData$provenance_not_linear>0.5)&(chaptersData$id>min(chaptersData$id)) , select=c('part_id','provenance_not_linear'))
if(nrow(byChaps)>0){
byChaps$classe="provenance_not_linear"
byChaps$issueCode="max"
byChaps$error_value=round(100*byChaps$provenance_not_linear,2)
byChaps$delta = byChaps$provenance_not_linear
provenanceLinearity = byChaps
}
####### Provenance Future
byChaps=subset(chaptersData, (chaptersData$provenance_future>0.5) &(chaptersData$id>min(chaptersData$id)) , select=c('part_id','provenance_future'))
if(nrow(byChaps)>0){
byChaps$classe="provenance_future"
byChaps$issueCode="max"
byChaps$error_value=round(100*byChaps$provenance_future,2)
byChaps$delta = byChaps$provenance_future
provenanceFuture = byChaps
}
####### Provenance Past
byChaps=subset(chaptersData, (chaptersData$provenance_past>0.3)&(chaptersData$id<max(chaptersData$id)) , select=c('part_id','provenance_past'))
if(nrow(byChaps)>0){
byChaps$classe="provenance_past"
byChaps$issueCode="TransProvShift"
byChaps$error_value=round(100*byChaps$provenance_past,2)
byChaps$delta = byChaps$provenance_past
provenancePast = byChaps
}
####### Destination Linearity
byChaps=subset(chaptersData, (chaptersData$destination_not_linear >0.5)&(chaptersData$id<max(chaptersData$id)) , select=c('part_id','destination_not_linear'))
if(nrow(byChaps)>0){
byChaps$classe="destination_not_linear"
byChaps$issueCode="TransDestShift"
byChaps$error_value=round(100*byChaps$destination_not_linear,2)
byChaps$delta=byChaps$destination_not_linear
destinationLinearity = byChaps
}
####### Destination Future
byChaps=subset(chaptersData, (chaptersData$destination_future >0.3)&(chaptersData$id<max(chaptersData$id)) , select=c('part_id','destination_future'))
if(nrow(byChaps)>0){
byChaps$classe="destination_future"
byChaps$issueCode="max"
byChaps$error_value=round(100*byChaps$destination_future,2)
byChaps$delta=byChaps$destination_future
destinationFuture = byChaps
}
####### Destination Past
byChaps=subset(chaptersData, (chaptersData$destination_past >0.3)&(chaptersData$id<max(chaptersData$id)) , select=c('part_id','destination_past'))
if(nrow(byChaps)>0){
byChaps$classe="destination_past"
byChaps$issueCode="max"
byChaps$error_value=round(100*byChaps$destination_past,2)
byChaps$delta=byChaps$destination_past
destinationPast = byChaps
}
########### Session end
byChaps = chaptersData[(DoubleMADsFromMedian(chaptersData$rupture_tx)>2)&
(chaptersData$rupture_tx>median(chaptersData$rupture_tx)&(chaptersData$id<max(chaptersData$id)) ),c('part_id','rupture_tx')]
if(nrow(byChaps)>0){
byChaps$classe="rupture_tx"
byChaps$issueCode="max"
byChaps$error_value=round(100*byChaps$rupture_tx,2)
byChaps$delta=round(100*byChaps$rupture_tx,2)
maxRSStops =   byChaps
}
####### Max Stops
byChaps = chaptersData[(DoubleMADsFromMedian(chaptersData$norecovery_tx)>2)&
(chaptersData$norecovery_tx>median(chaptersData$norecovery_tx) )&(chaptersData$id<max(chaptersData$id)),c('part_id','norecovery_tx')]
if(nrow(byChaps)>0){
byChaps$classe="norecovery_tx"
byChaps$issueCode="max"
byChaps$delta=byChaps$norecovery_tx - median(chaptersData$norecovery_tx)
byChaps$error_value = round(100*byChaps$norecovery_tx,2)
maxFinalStops =   byChaps
}
####### Recovery ANormal
byChaps = subset(chaptersData, (chaptersData$resume_abnormal_tx > 0.5)&(chaptersData$id<max(chaptersData$id)) , select=c('part_id','resume_abnormal_tx'))
if(nrow(byChaps)>0){
byChaps$classe="resume_abnormal_tx"
byChaps$issueCode="max"
byChaps$error_value=round(100*byChaps$resume_abnormal_tx,2)
byChaps$delta = byChaps$resume_abnormal_tx;
resumeLinearity =   byChaps
}
####### Recovery Past
byChaps = subset(chaptersData, (chaptersData$resume_past > 0.33)&(chaptersData$id<max(chaptersData$id)) , select=c('part_id','resume_past'))
if(nrow(byChaps)>0){
byChaps$classe="resume_past"
byChaps$issueCode="max"
byChaps$error_value=round(100*byChaps$resume_past,2)
byChaps$delta = byChaps$resume_past
recoveryPast =   byChaps
}
####### Recovery Future
byChaps = subset(chaptersData, (chaptersData$resume_future > 0.33)&(chaptersData$id<max(chaptersData$id)) , select=c('part_id','resume_future'))
if(nrow(byChaps)>0){
byChaps$classe="resume_future"
byChaps$issueCode="max"
byChaps$delta = byChaps$resume_future
byChaps$error_value=round(100*byChaps$resume_future,2)
recoveryFuture =   byChaps
}
##############CONCATENATE EVERYTHING##############
names(minInterest)[c(1,2)]=
names(minVisits)[c(1,2)]=
names(minReaders)[c(1,2)]=
names(maxRereadings)[c(1,2)]=
names(maxDijRereadings)[c(1,2)]=
names(maxConjRereadings)[c(1,2)]=
names(readingLinearity)[c(1,2)]=
names(provenanceLinearity)[c(1,2)]=
names(provenancePast)[c(1,2)]=
names(provenanceFuture)[c(1,2)]=
names(destinationLinearity)[c(1,2)]=
names(destinationPast)[c(1,2)]=
names(destinationFuture)[c(1,2)]=
names(maxRSStops)[c(1,2)]=
names(maxFinalStops)[c(1,2)]=
names(resumeLinearity)[c(1,2)]=
names(recoveryPast)[c(1,2)]=
names(recoveryFuture)[c(1,2)]=
c("part_id","value")
facts =
rbind(
minInterest,
minVisits,
minReaders,
maxRereadings,
maxDijRereadings,
maxConjRereadings,
readingLinearity,
provenanceLinearity,
provenancePast,
provenanceFuture,
destinationLinearity,
destinationPast,
destinationFuture,
maxRSStops,
maxFinalStops,
resumeLinearity,
recoveryFuture,
recoveryPast)
rownames(facts)=NULL
if(dospeed){
names(minSpeed)[c(1,2)]=
names(maxSpeed)[c(1,2)]=c("part_id","value")
facts =  rbind(facts,minSpeed,maxSpeed)
}
return(facts)
}
###################################################### DO
params = fromJSON(jsonObj)
do_course(params$csv_f,params$json_f)
#csv_f = "/home/madjid/Dropbox/rcoreada/Dataset/1885491/data.csv"
#json_f = "/home/madjid/Dropbox/rcoreada/Dataset/1885491/structure.json"
#do_course(csv_f,json_f)
####################################### END #####################################################################
}
###############  INITIAL FULLDATA ###########################
initfulldata <- function(home){
#
setwd(home)
### RUN ONCE
#fulldata = read.csv2('USER_COURSE_VISUALISATION.csv', stringsAsFactors=FALSE)
#save(fulldata,file='fulldata.rdata')
#load('fulldata.rdata')
courseIds = unique(fulldata$course_id)
ncourses=length(courseIds)
for(i in 1:ncourses){
course_id = courseIds[i]
dir.create(file.path(home, course_id), showWarnings = FALSE)
setwd(paste(home,course_id,sep='/'))
#print(paste('Cours', i,'/',ncourses))
#setwd(paste(BaseURL,selectedCourse, sep='/'))
data = fulldata[which(fulldata$course_id==course_id),]
write.csv2(data,file='data.csv')
setwd(home)
}
alljsons = list.files(paste(home,'jsons',sep='/'))
################ BEGIN FOR
for(i in 1:length(alljsons)){
#print(paste('Cours structure', i,'/',length(alljsons)))
selectedCoursePath = paste(home,'jsons',sep='/')
setwd(selectedCoursePath)
jsonstructure <- fromJSON(alljsons[i])
courseId = jsonstructure$id
id_counter = 0;
structure = data.frame(id=id_counter, part_id=jsonstructure$id, parent_id=0,title=jsonstructure$title,type=jsonstructure$subtype,
slug=jsonstructure$slug, element_id=jsonstructure$elementId, course_id= courseId)
ntomes = nrow(jsonstructure$children)
if(ntomes>0)
for(t_counter in 1:ntomes){
itome = as.data.frame(jsonstructure$children[t_counter,])
tome.structure = data.frame(id=-99, part_id=itome$id, parent_id=structure[1,'part_id'],title=itome$title, type=itome$subtype,
slug=itome$slug, element_id=itome$elementId,course_id= courseId)
structure = rbind(structure , tome.structure)
chaps= as.data.frame(itome$children)
nchaps =  nrow(chaps)
if(nchaps>0)
for(ch_counter in 1:nchaps){
id_counter = id_counter + 1
ichap =  as.data.frame(chaps[ch_counter,])
chap.structure = data.frame(id=id_counter, part_id=ichap$id, parent_id=itome$id,title=ichap$title,type=ichap$subtype,
slug=ichap$slug, element_id=ichap$elementId,course_id= courseId)
structure = rbind(structure , chap.structure)
parts =  as.data.frame(ichap$children)
npart = nrow(parts)
if(npart>0)
for(part_counter in 1:npart ){
id_counter = id_counter + 1
ipart =  as.data.frame(ichap$children)[part_counter,]
part.structure = data.frame(id = id_counter, part_id=ipart$id, parent_id=ichap$id,title=ipart$title,type=ipart$subtype,
slug='', element_id=ipart$elementId,course_id= courseId)
structure = rbind(structure , part.structure)
}
}
}
setwd(home)
setwd(as.character(courseId))
cat(toJSON(jsonstructure), file="structure.json")
save(structure, file="structure.rdata")
setwd(home)
}############### END FOR
}
#####################################
#library('jsonlite')
#options(stringsAsFactors=FALSE)
#library('Rserve')
### STARTING
#Rserve(args='--vanilla')
### SHUTING
#require("RSclient")
#c <- RSconnect()
#RSshutdown(c)
do_verification <- function(code){
rawd = paste("/home/madjid/dev/CoReaDa/rawdata",code,sep='/')
cdurl = paste("/home/madjid/dev/CoReaDa/coursesdata",code,sep='/')
coreaDataURL = "/home/madjid/dev/CoReaDa/coursesdata"
setwd(rawd)
load('data.rdata')
load('structure.rdata')
load('PartData.rdata')
load('RS.rdata')
load('Interest.rdata')
load('Reads.rdata')
load('Ruptures.rdata')
load('partFollow.rdata')
indicators = list(data=data, structure=structure, RS=RS , Interest=Interest,Reads=Reads,Ruptures=Ruptures,partFollow=partFollow)
dir.create(file.path(coreaDataURL,code), showWarnings = FALSE)
courseDataURL=paste(coreaDataURL,code,sep='/')
CourseDataCalc = course_data_calculation(data,structure, indicators)
CourseData=CourseDataCalc$CourseData
PartData = CourseDataCalc$PartData
TransitionsData =  CourseDataCalc$TransitionsData
save(PartData,file='PartData.rdata')
save(CourseData,file='CourseData.rdata')
meltParts=melt(PartData, id.vars = 'id')
meltedCourseStats = melt(CourseData,  id.vars ="id")
meltedCourseData = rbind(meltParts,meltedCourseStats)
if(nrow(meltedCourseData[is.nan(meltedCourseData$value),])>0) meltedCourseData[is.nan(meltedCourseData$value),]$value=0
if(nrow(meltedCourseData[is.na(meltedCourseData$value),])>0) meltedCourseData[is.na(meltedCourseData$value),]$value=0
facts = course_issues_calculation(data, structure,PartData, CourseData$dospeed)
save(facts, file="facts.rdata")
CourseData.json = toJSON(meltedCourseData)
cat(CourseData.json, file=paste(courseDataURL,"data.json",sep='/'))
TransitionsData.json = toJSON(TransitionsData)
cat(TransitionsData.json, file=paste(courseDataURL,"navigation.json",sep='/'))
facts.json = toJSON(facts)
cat(facts.json, file=paste(courseDataURL,"facts.json",sep='/'))
print('COREADA OK!')
}
do_verification('2766951')
do_verification('2778161')
do_verification('2984401')
do_verification('3013711')
do_verification('3432066')
do_verification('1885491')
do_verification('1946386')
do_verification('3522386')
do_verification('3522386')
do_verification('3522386')
